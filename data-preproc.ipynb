{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helper_fxns as hf\n",
    "import importlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pylab import get_cmap\n",
    "import requests\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(input_path,'r') as f:\n",
    "    print('Parsing annotation files')\n",
    "    \n",
    "    bboxes = []\n",
    "    imgs = set()\n",
    "    for line in f:\n",
    "        output = B_box(line.strip().split(','))\n",
    "        bboxes.append(output)\n",
    "        imgs.add(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bbox in bboxes:\n",
    "    img = np.load(bbox['filepath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class B_box(object):    \n",
    "    def __init__(self, filename,x1,y1,z1,x2,y2,z2,class_name):\n",
    "        self.filename = filename\n",
    "        self.class_name = class_name\n",
    "        coords = {}\n",
    "        coords['x']=[x1,x2]\n",
    "        coords['y']=[y1,y2]\n",
    "        coords['z']=[z1,z2]\n",
    "        \n",
    "    def get_pixels_in_box(self, img):\n",
    "        return None\n",
    "        \n",
    "    def get_dims(self):\n",
    "        return [coords['x'][1] - coords['x'][0],\n",
    "                coords['y'][1] - coords['y'][0],\n",
    "                coords['z'][1] - coords['z'][0]]\n",
    "    \n",
    "    def random_flip_bbox(self):\n",
    "        dims = np.transpose(img_bbox, np.random.permutation([0,1,2]))\n",
    "        dims = np.transpose(dims, np.random.permutation([0,1,2]))\n",
    "        return [x[1] - x[0], y[1] - y[0], z[1] - z[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bbox():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img, bbox = rotate_bbox(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_image(img, angle):\n",
    "    \"\"\"Rotates an entire image, expanding the bboxes\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def double_bbox(bbox, img, dx, dy):\n",
    "    \"\"\"Create a duplicate of a bbox at a distance dx and dy from the original bbox\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_bbox(bbox, img):\n",
    "    \"\"\"Remove a bbox and replace it with the \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_bbox(bbox, img, angles):\n",
    "    \"\"\"Randomly flips/rotates a bbox and its contents by 90/180/270 degrees\"\"\"\n",
    "    angle = np.random.choice()\n",
    "    img = np.transpose(img, (1,0,2))\n",
    "    x1 = bbox['x1']\n",
    "    x2 = bbox['x2']\n",
    "    y1 = bbox['y1']\n",
    "    y2 = bbox['y2']\n",
    "    if angle == 270:\n",
    "        bbox['x1'] = y1\n",
    "        bbox['x2'] = y2\n",
    "        bbox['y1'] = cols - x2\n",
    "        bbox['y2'] = cols - x1\n",
    "    elif angle == 180:\n",
    "        bbox['x2'] = cols - x1\n",
    "        bbox['x1'] = cols - x2\n",
    "        bbox['y2'] = rows - y1\n",
    "        bbox['y1'] = rows - y2\n",
    "    elif angle == 90:\n",
    "        bbox['x1'] = rows - y2\n",
    "        bbox['x2'] = rows - y1\n",
    "        bbox['y1'] = x1\n",
    "        bbox['y2'] = x2     \n",
    "    \n",
    "    img = np.transpose(img, (1,0,2))\n",
    "    img = np.flip(img, 1)\n",
    "    if angle == 180:\n",
    "        img = np.transpose(img, (1,0,2))\n",
    "        img = np.flip(img, 1)\n",
    "        \n",
    "        \n",
    "\t\t\telif angle == 180:\n",
    "\t\t\t\timg = cv2.flip(img, -1)\n",
    "\t\t\telif angle == 90:\n",
    "\t\t\t\timg = np.transpose(img, (1,0,2))\n",
    "\t\t\t\timg = cv2.flip(img, 1)\n",
    "\t\t\telif angle == 0:\n",
    "\t\t\t\tpass\n",
    "\n",
    "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
    "\t\t\t\tx1 = bbox['x1']\n",
    "\t\t\t\tx2 = bbox['x2']\n",
    "\t\t\t\ty1 = bbox['y1']\n",
    "\t\t\t\ty2 = bbox['y2']\n",
    "\t\t\t\tif angle == 270:\n",
    "\t\t\t\t\tbbox['x1'] = y1\n",
    "\t\t\t\t\tbbox['x2'] = y2\n",
    "\t\t\t\t\tbbox['y1'] = cols - x2\n",
    "\t\t\t\t\tbbox['y2'] = cols - x1\n",
    "\t\t\t\telif angle == 180:\n",
    "\t\t\t\t\tbbox['x2'] = cols - x1\n",
    "\t\t\t\t\tbbox['x1'] = cols - x2\n",
    "\t\t\t\t\tbbox['y2'] = rows - y1\n",
    "\t\t\t\t\tbbox['y1'] = rows - y2\n",
    "\t\t\t\telif angle == 90:\n",
    "\t\t\t\t\tbbox['x1'] = rows - y2\n",
    "\t\t\t\t\tbbox['x2'] = rows - y1\n",
    "\t\t\t\t\tbbox['y1'] = x1\n",
    "\t\t\t\t\tbbox['y2'] = x2        \n",
    "\t\t\t\telif angle == 0:\n",
    "\t\t\t\t\tpass\n",
    "    return bbox\n",
    "\n",
    "def flip_bbox(bbox, img, flip_type):\n",
    "    \"\"\"Rotates a bbox and its contents by 90/180/270 degrees\"\"\"\n",
    "    if flip_type == 'horizontal':\n",
    "        for bbox in img_data_aug['bboxes']:\n",
    "            x1 = bbox['x1']\n",
    "            x2 = bbox['x2']\n",
    "            bbox['x2'] = cols - x1\n",
    "            bbox['x1'] = cols - x2\n",
    "    if flip_type == 'horizontal':\n",
    "        for bbox in img_data_aug['bboxes']:\n",
    "            x1 = bbox['x1']\n",
    "            x2 = bbox['x2']\n",
    "            bbox['x2'] = cols - x1\n",
    "            bbox['x1'] = cols - x2\n",
    "            \n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift_bbox(bbox, img, dx, dy):\n",
    "    \"\"\"Shifts bbox and its contents to a random nearby location.\"\"\"\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bbox in bboxes:\n",
    "    shift_bbox_with_pixels(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helper_fxns' from '/Users/clintonwang/Documents/Work/LI-RADS/helper_fxns.py'>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img,_ = hf.dcm_load('./dcm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img1 = img[:,:,20:25]\n",
    "img1 = np.array([list(img1), list(img1), list(img1)])\n",
    "img1 = np.transpose(img1, (1,2,3,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('img3', img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.where(Y1[0, :, -1] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall approach\n",
    "This is a tool for classifying precontrast and 20s postcontrast MRIs (into LI-RADS stages / predicting survival?).\n",
    "\n",
    "#### Training\n",
    "-In mini-batches:\n",
    "1. Import pre/20s DICOMs\n",
    "2. Register pre to 20s\n",
    "3. Segment whole liver\n",
    "4. Obtain labels for HCC/non-HCC, as well as (HCC severity or survival?)\n",
    "5. For HCC labels, calculate and store embeddings (feature values)\n",
    "6. Train CNN on all\n",
    "\n",
    "-After CNN is trained, then:\n",
    "7. Train feature engineered network on HCC labels\n",
    "\n",
    "#### Test pipeline:\n",
    "1. Import pre/20s DICOMs\n",
    "2. Register pre to 20s\n",
    "3. Segment whole liver\n",
    "4. Use CNN to classify as HCC/non-HCC\n",
    "5. If HCC, calculate features values\n",
    "6. If HCC, use feature engineered network to predict label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_pipeline(pre_dcm_fns, post_dcm_fns, labels):\n",
    "    \"\"\"\n",
    "    pre_dcm_fn is the precontrast image, and post_dcm_fn is the postcontrast image\n",
    "    1. Import pre/20s DICOMs\n",
    "    2. Register pre to 20s\n",
    "    3. Segment whole liver\n",
    "    4. Obtain labels for HCC/non-HCC, as well as (HCC severity or survival?)\n",
    "    5. For HCC labels, calculate and store embeddings (feature values)\n",
    "    6. Train CNN on all\n",
    "    7. Train feature engineered network on HCC labels\n",
    "    \"\"\"\n",
    "    train_frac = 0.7\n",
    "    data_size = len(pre_dcm_fns)\n",
    "    \n",
    "    # TODO: do a proper k-fold x-validation split\n",
    "    X_cnn_train = X_cnn[:data_size*train_frac]\n",
    "    X_cnn_val = X_cnn[data_size*train_frac:]\n",
    "    \n",
    "    for x in range(data_size):\n",
    "        pre_dcm_fn = pre_dcm_fns[x]\n",
    "        post_dcm_fn = post_dcm_fn[x]\n",
    "        label = labels[x]\n",
    "        \n",
    "        pre_img = hf.dcm_load(pre_dcm_fn)\n",
    "        post_img = hf.dcm_load(post_dcm_fn)\n",
    "\n",
    "        pre_img = seg_liver(pre_img)\n",
    "        post_img = seg_liver(post_img)\n",
    "        \n",
    "        y_cnn = label['is-hcc']\n",
    "        label.pop('is-hcc')\n",
    "        X_cnn = [pre_img, post_img, label]\n",
    "        \n",
    "        \"\"\"if y_cnn:\n",
    "            features = get_features(pre_img, post_img, label)\n",
    "            \n",
    "            # rfm is random forest model\n",
    "            y_rfm = label\n",
    "            X_rfm = [pre_img, post_img, label]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dcm_2_ni(fn):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reg_dcms(moving, target):\n",
    "    pass\n",
    "\n",
    "def seg_liver(img):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
