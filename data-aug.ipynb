{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helper_fxns as hf\n",
    "import transforms as tr\n",
    "import importlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pylab import get_cmap\n",
    "import requests\n",
    "import sys\n",
    "from skimage.draw import polygon\n",
    "import cv2\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downsample(img, mrn, aug_rois, scale=0.4):    \n",
    "    img = tr.scaley(tr.scalex(img, scale), scale)\n",
    "    np.save(\"imgs_aug\\\\\"+mrn, img)\n",
    "    \n",
    "    aug_rois += [[mrn+\".npy\"] + [str(round(int(roi[x])*scale)) for x in range(1,5)] + roi[5:]\n",
    "                for roi in rois if roi[0] == mrn+\".npy\"]\n",
    "    \n",
    "    return img, aug_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug_noise(img, mrn, aug_rois):\n",
    "    mrn_rois = [x for x in rois if x[0] == mrn+\".npy\"]\n",
    "    \n",
    "    k_size = 5\n",
    "    np.save(\"imgs_aug\\\\\"+mrn+\"_b\"+str(k_size), cv2.blur(img,(k_size,k_size)))\n",
    "    for roi in mrn_rois:\n",
    "        aug_rois.append([mrn+\"_b\"+str(k_size)+\".npy\"] + roi[1:])\n",
    "    \n",
    "    return aug_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug_scaling(img, mrn, aug_rois):\n",
    "    mrn_rois = [x for x in rois if x[0] == mrn+\".npy\"]\n",
    "    \n",
    "    for scale in [1.15,1.3]:\n",
    "        np.save(\"imgs_aug\\\\\"+mrn+\"_sx\"+str(scale)[-1], tr.scalex(img, scale))\n",
    "        for roi in mrn_rois:\n",
    "            aug_rois.append([mrn+\"_sx\"+str(scale)[-1]+\".npy\",\n",
    "                             str(round(int(roi[1])*scale)), str(round(int(roi[2])*scale))] + roi[3:])\n",
    "            \n",
    "        np.save(\"imgs_aug\\\\\"+mrn+\"_sy\"+str(scale)[-1], tr.scaley(img, scale))\n",
    "        for roi in mrn_rois:\n",
    "            aug_rois.append([mrn+\"_sy\"+str(scale)[-1]+\".npy\"] + roi[1:3] +\n",
    "                            [str(round(int(roi[3])*scale)), str(round(int(roi[4])*scale))] + roi[5:])\n",
    "            \n",
    "        np.save(\"imgs_aug\\\\\"+mrn+\"_sz\"+str(scale)[-1], tr.scalez(img, scale))\n",
    "        for roi in mrn_rois:\n",
    "            aug_rois.append([mrn+\"_sz\"+str(scale)[-1]+\".npy\"] + roi[1:5] +\n",
    "                            [str(round(int(roi[5])*scale)), str(round(int(roi[6])*scale))] + roi[7:])\n",
    "    \n",
    "    return aug_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug_rotation(img, mrn, aug_rois):\n",
    "    mrn_rois = [x for x in rois if x[0] == mrn+\".npy\"]\n",
    "    \n",
    "    for angle in [15,30,345,330]:\n",
    "        np.save(\"imgs_aug\\\\\"+mrn+\"_r\"+str(angle), tr.rotate(img, angle))\n",
    "        for roi in mrn_rois:\n",
    "            aug_rois.append([mrn+\"_r\"+str(angle)+\".npy\"] + roi[1:])\n",
    "    \n",
    "    return aug_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"train_list.txt\", \"r\") as f:\n",
    "    rois = [x.split(',') for x in f.read().split(\"\\n\")]\n",
    "aug_rois = []#[roi.split(\",\") for roi in rois]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for mrn in os.listdir(\"imgs\\\\\"):\n",
    "    img = np.load(\"imgs\\\\\"+mrn)\n",
    "    img, aug_rois = downsample(img, mrn[:-4], aug_rois)\n",
    "    np.save(\"imgs_aug\\\\\"+mrn, img)\n",
    "    aug_rois = aug_rotation(img, mrn[:-4], aug_rois)\n",
    "    aug_rois = aug_scaling(img, mrn[:-4], aug_rois)\n",
    "    #aug_rois = aug_noise(img, mrn[:-4], aug_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('aug_train_list.txt', 'w') as f:\n",
    "    for roi in aug_rois:\n",
    "        f.write(\",\".join(roi) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-238-372df73e36d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Parsing annotation files'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_path' is not defined"
     ]
    }
   ],
   "source": [
    "with open(input_path,'r') as f:\n",
    "    print('Parsing annotation files')\n",
    "    \n",
    "    bboxes = []\n",
    "    imgs = set()\n",
    "    for line in f:\n",
    "        output = B_box(line.strip().split(','))\n",
    "        bboxes.append(output)\n",
    "        imgs.add(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bbox in bboxes:\n",
    "    img = np.load(bbox['filepath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class B_box(object):    \n",
    "    def __init__(self, filename,x1,y1,z1,x2,y2,z2,class_name):\n",
    "        self.filename = filename\n",
    "        self.class_name = class_name\n",
    "        coords = {}\n",
    "        coords['x']=[x1,x2]\n",
    "        coords['y']=[y1,y2]\n",
    "        coords['z']=[z1,z2]\n",
    "        \n",
    "    def get_pixels_in_box(self, img):\n",
    "        return None\n",
    "        \n",
    "    def get_dims(self):\n",
    "        return [coords['x'][1] - coords['x'][0],\n",
    "                coords['y'][1] - coords['y'][0],\n",
    "                coords['z'][1] - coords['z'][0]]\n",
    "    \n",
    "    def random_flip_bbox(self):\n",
    "        dims = np.transpose(img_bbox, np.random.permutation([0,1,2]))\n",
    "        dims = np.transpose(dims, np.random.permutation([0,1,2]))\n",
    "        return [x[1] - x[0], y[1] - y[0], z[1] - z[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bbox():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img, bbox = rotate_bbox(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def double_bbox(bbox, img, dx, dy):\n",
    "    \"\"\"Create a duplicate of a bbox at a distance dx and dy from the original bbox\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_bbox(bbox, img):\n",
    "    \"\"\"Remove a bbox and replace it with the \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_bbox(bbox, img, angles):\n",
    "    \"\"\"Randomly flips/rotates a bbox and its contents by 90/180/270 degrees\"\"\"\n",
    "    angle = np.random.choice()\n",
    "    img = np.transpose(img, (1,0,2))\n",
    "    x1 = bbox['x1']\n",
    "    x2 = bbox['x2']\n",
    "    y1 = bbox['y1']\n",
    "    y2 = bbox['y2']\n",
    "    if angle == 270:\n",
    "        bbox['x1'] = y1\n",
    "        bbox['x2'] = y2\n",
    "        bbox['y1'] = cols - x2\n",
    "        bbox['y2'] = cols - x1\n",
    "    elif angle == 180:\n",
    "        bbox['x2'] = cols - x1\n",
    "        bbox['x1'] = cols - x2\n",
    "        bbox['y2'] = rows - y1\n",
    "        bbox['y1'] = rows - y2\n",
    "    elif angle == 90:\n",
    "        bbox['x1'] = rows - y2\n",
    "        bbox['x2'] = rows - y1\n",
    "        bbox['y1'] = x1\n",
    "        bbox['y2'] = x2     \n",
    "    \n",
    "    img = np.transpose(img, (1,0,2))\n",
    "    img = np.flip(img, 1)\n",
    "    if angle == 180:\n",
    "        img = np.transpose(img, (1,0,2))\n",
    "        img = np.flip(img, 1)\n",
    "        \n",
    "        \n",
    "\t\t\telif angle == 180:\n",
    "\t\t\t\timg = cv2.flip(img, -1)\n",
    "\t\t\telif angle == 90:\n",
    "\t\t\t\timg = np.transpose(img, (1,0,2))\n",
    "\t\t\t\timg = cv2.flip(img, 1)\n",
    "\t\t\telif angle == 0:\n",
    "\t\t\t\tpass\n",
    "\n",
    "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
    "\t\t\t\tx1 = bbox['x1']\n",
    "\t\t\t\tx2 = bbox['x2']\n",
    "\t\t\t\ty1 = bbox['y1']\n",
    "\t\t\t\ty2 = bbox['y2']\n",
    "\t\t\t\tif angle == 270:\n",
    "\t\t\t\t\tbbox['x1'] = y1\n",
    "\t\t\t\t\tbbox['x2'] = y2\n",
    "\t\t\t\t\tbbox['y1'] = cols - x2\n",
    "\t\t\t\t\tbbox['y2'] = cols - x1\n",
    "\t\t\t\telif angle == 180:\n",
    "\t\t\t\t\tbbox['x2'] = cols - x1\n",
    "\t\t\t\t\tbbox['x1'] = cols - x2\n",
    "\t\t\t\t\tbbox['y2'] = rows - y1\n",
    "\t\t\t\t\tbbox['y1'] = rows - y2\n",
    "\t\t\t\telif angle == 90:\n",
    "\t\t\t\t\tbbox['x1'] = rows - y2\n",
    "\t\t\t\t\tbbox['x2'] = rows - y1\n",
    "\t\t\t\t\tbbox['y1'] = x1\n",
    "\t\t\t\t\tbbox['y2'] = x2        \n",
    "\t\t\t\telif angle == 0:\n",
    "\t\t\t\t\tpass\n",
    "    return bbox\n",
    "\n",
    "def flip_bbox(bbox, img, flip_type):\n",
    "    \"\"\"Rotates a bbox and its contents by 90/180/270 degrees\"\"\"\n",
    "    if flip_type == 'horizontal':\n",
    "        for bbox in img_data_aug['bboxes']:\n",
    "            x1 = bbox['x1']\n",
    "            x2 = bbox['x2']\n",
    "            bbox['x2'] = cols - x1\n",
    "            bbox['x1'] = cols - x2\n",
    "    if flip_type == 'horizontal':\n",
    "        for bbox in img_data_aug['bboxes']:\n",
    "            x1 = bbox['x1']\n",
    "            x2 = bbox['x2']\n",
    "            bbox['x2'] = cols - x1\n",
    "            bbox['x1'] = cols - x2\n",
    "            \n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift_bbox(bbox, img, dx, dy):\n",
    "    \"\"\"Shifts bbox and its contents to a random nearby location.\"\"\"\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bbox in bboxes:\n",
    "    shift_bbox_with_pixels(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helper_fxns' from '/Users/clintonwang/Documents/Work/LI-RADS/helper_fxns.py'>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img,_ = hf.dcm_load('./dcm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img1 = img[:,:,20:25]\n",
    "img1 = np.array([list(img1), list(img1), list(img1)])\n",
    "img1 = np.transpose(img1, (1,2,3,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('img3', img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.where(Y1[0, :, -1] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall approach\n",
    "This is a tool for classifying precontrast and 20s postcontrast MRIs (into LI-RADS stages / predicting survival?).\n",
    "\n",
    "#### Training\n",
    "-In mini-batches:\n",
    "1. Import pre/20s DICOMs\n",
    "2. Register pre to 20s\n",
    "3. Segment whole liver\n",
    "4. Obtain labels for HCC/non-HCC, as well as (HCC severity or survival?)\n",
    "5. For HCC labels, calculate and store embeddings (feature values)\n",
    "6. Train CNN on all\n",
    "\n",
    "-After CNN is trained, then:\n",
    "7. Train feature engineered network on HCC labels\n",
    "\n",
    "#### Test pipeline:\n",
    "1. Import pre/20s DICOMs\n",
    "2. Register pre to 20s\n",
    "3. Segment whole liver\n",
    "4. Use CNN to classify as HCC/non-HCC\n",
    "5. If HCC, calculate features values\n",
    "6. If HCC, use feature engineered network to predict label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_pipeline(pre_dcm_fns, post_dcm_fns, labels):\n",
    "    \"\"\"\n",
    "    pre_dcm_fn is the precontrast image, and post_dcm_fn is the postcontrast image\n",
    "    1. Import pre/20s DICOMs\n",
    "    2. Register pre to 20s\n",
    "    3. Segment whole liver\n",
    "    4. Obtain labels for HCC/non-HCC, as well as (HCC severity or survival?)\n",
    "    5. For HCC labels, calculate and store embeddings (feature values)\n",
    "    6. Train CNN on all\n",
    "    7. Train feature engineered network on HCC labels\n",
    "    \"\"\"\n",
    "    train_frac = 0.7\n",
    "    data_size = len(pre_dcm_fns)\n",
    "    \n",
    "    # TODO: do a proper k-fold x-validation split\n",
    "    X_cnn_train = X_cnn[:data_size*train_frac]\n",
    "    X_cnn_val = X_cnn[data_size*train_frac:]\n",
    "    \n",
    "    for x in range(data_size):\n",
    "        pre_dcm_fn = pre_dcm_fns[x]\n",
    "        post_dcm_fn = post_dcm_fn[x]\n",
    "        label = labels[x]\n",
    "        \n",
    "        pre_img = hf.dcm_load(pre_dcm_fn)\n",
    "        post_img = hf.dcm_load(post_dcm_fn)\n",
    "\n",
    "        pre_img = seg_liver(pre_img)\n",
    "        post_img = seg_liver(post_img)\n",
    "        \n",
    "        y_cnn = label['is-hcc']\n",
    "        label.pop('is-hcc')\n",
    "        X_cnn = [pre_img, post_img, label]\n",
    "        \n",
    "        \"\"\"if y_cnn:\n",
    "            features = get_features(pre_img, post_img, label)\n",
    "            \n",
    "            # rfm is random forest model\n",
    "            y_rfm = label\n",
    "            X_rfm = [pre_img, post_img, label]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dcm_2_ni(fn):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reg_dcms(moving, target):\n",
    "    pass\n",
    "\n",
    "def seg_liver(img):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
